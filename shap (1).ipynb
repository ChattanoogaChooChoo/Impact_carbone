{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08a9dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Features for Min-Max-Scalering:\n",
      " ['Monthly_Grocery_Bill', 'Vehicle_Monthly_Distance_Km', 'Waste_Bag_Weekly_Count', 'How_Long_TV_PC_Daily_Hour', 'How_Many_New_Clothes_Monthly', 'How_Long_Internet_Daily_Hour']\n",
      "5 Features for One-Hot-Encoding:\n",
      " ['Sex', 'Heating_Energy_Source', 'Transport_Vehicle_Type', 'Recycling', 'Cooking_With']\n",
      "6 Features for Min-Max-Scaling:\n",
      " ['Monthly_Grocery_Bill', 'Vehicle_Monthly_Distance_Km', 'Waste_Bag_Weekly_Count', 'How_Long_TV_PC_Daily_Hour', 'How_Many_New_Clothes_Monthly', 'How_Long_Internet_Daily_Hour']\n",
      "7 Features where we apply Ordinal-Encoding:\n",
      " ['Body_Type', 'Diet', 'How_Often_Shower', 'Social_Activity', 'Frequency_of_Traveling_by_Air', 'Waste_Bag_Size', 'Energy_efficiency']\n"
     ]
    }
   ],
   "source": [
    "# Import des librairies\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocessing import preprocess, selection_types_features, data_cleaning_import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from model import train_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89ce9788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "df = pd.read_csv(\"raw_data/Carbon_Emission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abdd0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path= \"raw_data/Carbon_Emission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5406aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('CarbonEmission', axis=1)\n",
    "y = df['CarbonEmission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eb290dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.1-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\tsand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (2.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\tsand\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.14.1)\n",
      "Downloading xgboost-2.1.1-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 6.6/124.9 MB 36.6 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 14.7/124.9 MB 38.4 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 23.6/124.9 MB 39.3 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 32.2/124.9 MB 39.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 41.4/124.9 MB 39.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 50.6/124.9 MB 40.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 58.5/124.9 MB 40.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 67.9/124.9 MB 40.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 75.5/124.9 MB 39.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 84.4/124.9 MB 40.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 93.8/124.9 MB 40.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 103.5/124.9 MB 40.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 113.0/124.9 MB 41.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  122.7/124.9 MB 41.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.8/124.9 MB 41.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.8/124.9 MB 41.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.8/124.9 MB 41.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 124.9/124.9 MB 33.2 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8deb07e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# train an XGBoost model\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "import shap\n",
    "\n",
    "# train an XGBoost model\n",
    "X, y = shap.datasets.california()\n",
    "model = xgboost.XGBRegressor().fit(X, y)\n",
    "\n",
    "# explain the model's predictions using SHAP\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "# visualize the first prediction's explanation\n",
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56267bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, dict_variables_ordinal_categorical=data_cleaning_import(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d9a7506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model (df, dict_variables_ordinal_categorical):\n",
    "\n",
    "    # Appel des fonction de preprocessing\n",
    "    variables_quantitative, variables_ordinal,variables_for_one_hot_encoded = selection_types_features(df)\n",
    "    cf, X_transformed = preprocess(df, variables_quantitative, variables_ordinal,variables_for_one_hot_encoded, dict_variables_ordinal_categorical)\n",
    "\n",
    "    #Choix du X et de la target d'entrainement\n",
    "    X_transformed = X_transformed\n",
    "    y = df[\"CarbonEmission\"]\n",
    "\n",
    "    # Diviser les données en ensembles d'entraînement et de test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, train_size=0.75, random_state=42)\n",
    "\n",
    "    # Initialiser le modèle avec les meilleurs paramètres trouvés\n",
    "    best_gbr = GradientBoostingRegressor(\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        max_features='sqrt',\n",
    "        min_samples_leaf=5,\n",
    "        min_samples_split=2,\n",
    "        n_estimators=900,\n",
    "        subsample=0.9,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Entraîner le modèle\n",
    "    best_gbr.fit(X_train, y_train)\n",
    "\n",
    "    return best_gbr,cf, X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e38d8497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Features for Min-Max-Scalering:\n",
      " ['Monthly_Grocery_Bill', 'Vehicle_Monthly_Distance_Km', 'Waste_Bag_Weekly_Count', 'How_Long_TV_PC_Daily_Hour', 'How_Many_New_Clothes_Monthly', 'How_Long_Internet_Daily_Hour']\n",
      "5 Features for One-Hot-Encoding:\n",
      " ['Sex', 'Heating_Energy_Source', 'Transport_Vehicle_Type', 'Recycling', 'Cooking_With']\n",
      "6 Features for Min-Max-Scaling:\n",
      " ['Monthly_Grocery_Bill', 'Vehicle_Monthly_Distance_Km', 'Waste_Bag_Weekly_Count', 'How_Long_TV_PC_Daily_Hour', 'How_Many_New_Clothes_Monthly', 'How_Long_Internet_Daily_Hour']\n",
      "7 Features where we apply Ordinal-Encoding:\n",
      " ['Body_Type', 'Diet', 'How_Often_Shower', 'Social_Activity', 'Frequency_of_Traveling_by_Air', 'Waste_Bag_Size', 'Energy_efficiency']\n"
     ]
    }
   ],
   "source": [
    "best_gbr,cf, X_train, X_test, y_train, y_test= train_model(df, dict_variables_ordinal_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b74bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de visualisation avec SHAP\n",
    "def visualize_shap(best_gbr, X_test):\n",
    "    # Utiliser TreeExplainer pour les modèles basés sur des arbres\n",
    "    explainer = shap.Explainer(best_gbr)\n",
    "\n",
    "    # Calculer les valeurs SHAP pour les données d'entraînement\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    # Visualisation globale : importance des features (summary plot)\n",
    "    shap.summary_plot(shap_values, X_test)\n",
    "\n",
    "    # Visualisation sous forme de barres pour l'importance moyenne\n",
    "    shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97607d2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'shap' has no attribute 'Explainer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Visualiser SHAP\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mvisualize_shap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_gbr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m, in \u001b[0;36mvisualize_shap\u001b[1;34m(best_gbr, X_test)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_shap\u001b[39m(best_gbr, X_test):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Utiliser TreeExplainer pour les modèles basés sur des arbres\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExplainer\u001b[49m(best_gbr)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Calculer les valeurs SHAP pour les données d'entraînement\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(X_test)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'shap' has no attribute 'Explainer'"
     ]
    }
   ],
   "source": [
    "# Visualiser SHAP\n",
    "visualize_shap(best_gbr, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babc3659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Scoring_impact_carbone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
